{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb2AqrO_J973"
      },
      "outputs": [],
      "source": [
        "#1.what is hypothesis testing in statistics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hypothesis testing is a statistical method used to make decisions about a\n",
        "population parameter based on sample data. It involves formulating two competing hypotheses\n",
        "(null and alternative) and determining whether there is enough evidence in the sample data\n",
        "to reject the null hypothesis."
      ],
      "metadata": {
        "id": "crK1HkkbKLSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.What is the null hypothesis, and how does it differ from the alternative hypothesis"
      ],
      "metadata": {
        "id": "c9nkAVLoKMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Null Hypothesis (\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ): This is the default assumption that there is no effect or no\n",
        " difference in the population. It is the hypothesis we aim to test against.\n",
        "Alternative Hypothesis (\n",
        "ğ»\n",
        "ğ‘\n",
        "H\n",
        "a\n",
        "â€‹\n",
        " ): This is the statement we want to test for, which suggests there is an effect or a difference.\n",
        "The null hypothesis is typically tested with the goal of rejecting it in favor of the alternative hypothesis."
      ],
      "metadata": {
        "id": "Er3WyARTKMEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.What is the significance level in hypothesis testing, and why is it important"
      ],
      "metadata": {
        "id": "JjeYwipAKMKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The significance level\n",
        " (\n",
        "ğ›¼\n",
        "Î±) is the threshold for deciding whether to reject the null hypothesis. Commonly set\n",
        "at 0.05 or 5%, it represents the probability of making a Type 1 error (rejecting the null hypothesis when it is true). It is important because it defines the level of confidence we require to make a decision."
      ],
      "metadata": {
        "id": "QQowahQ4KMOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.What does a P-value represent in hypothesis testing"
      ],
      "metadata": {
        "id": "gANDRYjZKMSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The P-value is the probability of obtaining a test statistic as extreme as,\n",
        "or more extreme than, the one observed, assuming the null hypothesis is true.\n",
        " It quantifies the evidence against the null hypothesis."
      ],
      "metadata": {
        "id": "gnXUS_5RKMV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.What does a P-value represent in hypothesis testing"
      ],
      "metadata": {
        "id": "xrhDPfG0KMaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "If P-value â‰¤\n",
        "ğ›¼\n",
        "Î±: Reject the null hypothesis (\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ). There is significant evidence to support the alternative hypothesis (\n",
        "ğ»\n",
        "ğ‘\n",
        "H\n",
        "a\n",
        "â€‹\n",
        " ).\n",
        "If P-value >\n",
        "ğ›¼\n",
        "Î±: Fail to reject the null hypothesis. There is not enough evidence to support the alternative hypothesis."
      ],
      "metadata": {
        "id": "BcZB8IqiMJHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.How do you interpret the P-value in hypothesis testing"
      ],
      "metadata": {
        "id": "RzB0wpJUKMem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "If P-value â‰¤\n",
        "ğ›¼\n",
        "Î±: Reject the null hypothesis (\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ). There is significant evidence to support the alternative hypothesis (\n",
        "ğ»\n",
        "ğ‘\n",
        "H\n",
        "a\n",
        "â€‹\n",
        " ).\n",
        "If P-value >\n",
        "ğ›¼\n",
        "Î±: Fail to reject the null hypothesis. There is not enough evidence to support the alternative hypothesis."
      ],
      "metadata": {
        "id": "P1MNFf7AMNrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.What are Type 1 and Type 2 errors in hypothesis testing"
      ],
      "metadata": {
        "id": "6Hzyjx9AKMjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Type 1 Error (\n",
        "ğ›¼\n",
        "Î±): Rejecting the null hypothesis when it is true. This is controlled by the significance level.\n",
        "Type 2 Error (\n",
        "ğ›½\n",
        "Î²): Failing to reject the null hypothesis when it is false. It is influenced by sample size, effect size, and variability."
      ],
      "metadata": {
        "id": "ajIeqy_NMTjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.What is the difference between a one-tailed and a two-tailed test in hypothesis testing"
      ],
      "metadata": {
        "id": "vcxxbrAEKMml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "One-tailed test: Tests for a specific direction of the effect (e.g., greater than or less than).\n",
        "Two-tailed test: Tests for any difference without specifying a direction (e.g., simply different)."
      ],
      "metadata": {
        "id": "1InJrHxzMXfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.What is the Z-test, and when is it used in hypothesis testing"
      ],
      "metadata": {
        "id": "MTz4FtqKKMqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A Z-test is used when the population variance is known, and the sample size is large (\n",
        "ğ‘›\n",
        ">\n",
        "30\n",
        "n>30). It tests whether the sample mean differs significantly from the population mean."
      ],
      "metadata": {
        "id": "G4XqEWs9Mbsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.How do you calculate the Z-score, and what does it represent in hypothesis testing"
      ],
      "metadata": {
        "id": "oxeDauXYKMuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The Z-score is calculated as:\n",
        "\n",
        "ğ‘\n",
        "=\n",
        "ğ‘¥\n",
        "Ë‰\n",
        "âˆ’\n",
        "ğœ‡\n",
        "ğœ\n",
        "/\n",
        "ğ‘›\n",
        "Z=\n",
        "Ïƒ/\n",
        "n\n",
        "â€‹\n",
        "\n",
        "x\n",
        "Ë‰\n",
        " âˆ’Î¼\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘¥\n",
        "Ë‰\n",
        "x\n",
        "Ë‰\n",
        " : Sample mean\n",
        "ğœ‡\n",
        "Î¼: Population mean\n",
        "ğœ\n",
        "Ïƒ: Population standard deviation\n",
        "ğ‘›\n",
        "n: Sample size\n",
        "The Z-score represents how many standard deviations the sample mean is from the population mean."
      ],
      "metadata": {
        "id": "6yXQqDH4MfB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.What is the T-distribution, and when should it be used instead of the normal distribution"
      ],
      "metadata": {
        "id": "2rUNfNSQKMy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The T-distribution is a probability distribution used when the sample size is small (\n",
        "ğ‘›\n",
        "<\n",
        "30\n",
        "n<30) or when the population standard deviation (\n",
        "ğœ\n",
        "Ïƒ) is unknown. It is similar to the normal distribution but has heavier tails, providing more conservative results.\n",
        "\n"
      ],
      "metadata": {
        "id": "1DlsydeuMjUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12.What is the difference between a Z-test and a T-test"
      ],
      "metadata": {
        "id": "1WbyBCTUKM18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z-test: Used when the population standard deviation is known and the sample size is large.\n",
        "T-test: Used when the population standard deviation is unknown and/or the sample size is small."
      ],
      "metadata": {
        "id": "hpZlQAP2Mo5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.What is the T-test, and how is it used in hypothesis testing"
      ],
      "metadata": {
        "id": "5M3Q0xGNKM5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A T-test is used to compare sample means to:\n",
        "\n",
        "A known value (one-sample T-test),\n",
        "Another sample (independent T-test), or\n",
        "Measurements within the same sample (paired T-test).\n",
        "It helps determine whether the observed differences are statistically significant."
      ],
      "metadata": {
        "id": "waTVtCMoMroh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "A confidence interval (CI) is a range of values, derived from sample data, that is likely to contain the true population parameter (e.g., a mean or proportion) with a specified level of confidence (e.g., 95%).\n",
        "\n",
        "Interpretation: If the confidence level is 95%, this means that if we were to take 100 random samples and calculate confidence intervals for each, about 95 of them would contain the true population parameter.\n",
        "Use in Results: Confidence intervals help quantify uncertainty in an estimate and are often used alongside point estimates (like means) to provide context about the precision of the results.\n"
      ],
      "metadata": {
        "id": "GXZnJAZeKM9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15.What is the margin of error, and how does it affect the confidence interval?\n",
        "The margin of error (MoE) represents the maximum expected difference between the sample estimate and the true population value due to sampling variability.\n",
        "\n",
        "Relationship to Confidence Interval:\n",
        "ConfidenceÂ Interval\n",
        "=\n",
        "PointÂ Estimate\n",
        "Â±\n",
        "MarginÂ ofÂ Error\n",
        "ConfidenceÂ Interval=PointÂ EstimateÂ±MarginÂ ofÂ Error\n",
        "The margin of error widens or narrows the interval depending on the sample size, variability, and confidence level.\n",
        "Factors Affecting MoE:\n",
        "Higher confidence levels (e.g., 99%) increase the margin of error, leading to wider intervals.\n",
        "Larger sample sizes decrease the margin of error, leading to narrower intervals."
      ],
      "metadata": {
        "id": "EcDyYnDIKNBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "Bayes' Theorem provides a mathematical framework for updating the probability of a hypothesis based on new evidence. It is expressed as:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Bâˆ£A)P(A)\n",
        "â€‹\n",
        "\n",
        "Key Terms:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B): Posterior probability (probability of\n",
        "ğ´\n",
        "A given\n",
        "ğµ\n",
        "B).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "P(A): Prior probability of\n",
        "ğ´\n",
        "A.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "P(Bâˆ£A): Likelihood of\n",
        "ğµ\n",
        "B given\n",
        "ğ´\n",
        "A.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(B): Marginal probability of\n",
        "ğµ\n",
        "B.\n",
        "Significance:\n",
        "\n",
        "It is essential in Bayesian inference, allowing incorporation of prior knowledge with observed data.\n",
        "Used in diverse fields like medical diagnosis, machine learning, and decision-making."
      ],
      "metadata": {
        "id": "ZLmwBK1DKNEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. What is the Chi-square distribution, and when is it used?\n",
        "The Chi-square distribution is a family of distributions that arise from the sum of the squares of independent standard normal variables. It is defined by degrees of freedom (df).\n",
        "\n",
        "Applications:\n",
        "Hypothesis testing for categorical data.\n",
        "Goodness-of-fit tests.\n",
        "Testing independence in contingency tables.\n",
        "Estimating population variance.\n"
      ],
      "metadata": {
        "id": "yxviMGGuKNI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "The Chi-square goodness of fit test evaluates whether an observed frequency distribution matches an expected distribution.\n",
        "\n",
        "Steps:\n",
        "Define the null hypothesis (\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ): The observed distribution matches the expected distribution.\n",
        "Calculate the test statistic:\n",
        "ğœ’\n",
        "2\n",
        "=\n",
        "âˆ‘\n",
        "(\n",
        "ğ‘‚\n",
        "ğ‘–\n",
        "âˆ’\n",
        "ğ¸\n",
        "ğ‘–\n",
        ")\n",
        "2\n",
        "ğ¸\n",
        "ğ‘–\n",
        "Ï‡\n",
        "2\n",
        " =âˆ‘\n",
        "E\n",
        "i\n",
        "â€‹\n",
        "\n",
        "(O\n",
        "i\n",
        "â€‹\n",
        " âˆ’E\n",
        "i\n",
        "â€‹\n",
        " )\n",
        "2\n",
        "\n",
        "â€‹\n",
        "\n",
        "where\n",
        "ğ‘‚\n",
        "ğ‘–\n",
        "O\n",
        "i\n",
        "â€‹\n",
        "  and\n",
        "ğ¸\n",
        "ğ‘–\n",
        "E\n",
        "i\n",
        "â€‹\n",
        "  are observed and expected frequencies, respectively.\n",
        "Compare\n",
        "ğœ’\n",
        "2\n",
        "Ï‡\n",
        "2\n",
        "  to the critical value from the Chi-square table (based on df and significance level).\n",
        "Reject or fail to reject\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " .\n"
      ],
      "metadata": {
        "id": "3mxKPjGfKNNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "The F-distribution is a probability distribution that arises when comparing two sample variances. It is asymmetric and defined by two degrees of freedom: one for the numerator and one for the denominator.\n",
        "\n",
        "Applications:\n",
        "Analysis of variance (ANOVA).\n",
        "Comparing variances in two populations.\n",
        "Regression model comparison."
      ],
      "metadata": {
        "id": "jWh1zXVaKNQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. What is an ANOVA test, and what are its assumptions?\n",
        "Analysis of Variance (ANOVA) tests whether the means of three or more groups are significantly different.\n",
        "\n",
        "Assumptions:\n",
        "\n",
        "Independence: Observations are independent.\n",
        "Normality: The data in each group are approximately normally distributed.\n",
        "Homogeneity of variance: All groups have equal variances.\n",
        "Purpose: It helps determine if at least one group mean differs without testing pairwise comparisons directly."
      ],
      "metadata": {
        "id": "yfg31896KNUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21.What are the different types of ANOVA tests?\n",
        "One-way ANOVA: Tests for mean differences among groups based on a single factor.\n",
        "Two-way ANOVA: Examines the impact of two factors and their interaction on the dependent variable.\n",
        "Repeated Measures ANOVA: Compares means within the same subjects under different conditions or over time."
      ],
      "metadata": {
        "id": "SyFDx4AjKNX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22.What is the F-test, and how does it relate to hypothesis testing?\n",
        "An F-test compares variances to assess whether two datasets have significantly different variances or to test specific hypotheses in models like ANOVA.\n",
        "\n",
        "Relation to Hypothesis Testing:\n",
        "Null Hypothesis (\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ): The variances (or model fits) are equal.\n",
        "Alternative Hypothesis (\n",
        "ğ»\n",
        "1\n",
        "H\n",
        "1\n",
        "â€‹\n",
        " ): The variances (or model fits) differ significantly.\n",
        "If the computed\n",
        "ğ¹\n",
        "F-statistic exceeds the critical value, reject\n",
        "ğ»\n",
        "0\n",
        "H\n",
        "0\n",
        "â€‹\n",
        " ."
      ],
      "metadata": {
        "id": "CmtKm3hgKNbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PRATICAL EXAMPLE"
      ],
      "metadata": {
        "id": "HaK3ZvXCKNiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "#interpret the results\n",
        "$@ Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python@\n",
        "<@ Implement a one-sample Z-test using Python to compare the sample mean with the population mean@\n",
        "B@ Perform a two-tailed Z-test using Python and visualize the decision region on a plot@\n",
        "-@ Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing@\n",
        "\u0018@ @\n",
        "\u001d@ Perform a paired sample T-test using Python and visualize the comparison results@\n",
        "\u0019@ Simulate data and perform both Z-test and T-test, then compare the results using Python@\n",
        "\u0016@ Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "\n",
        "1. Z-Test for Comparing a Sample Mean to a Population Mean\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference.\")\n",
        "    return z_score, p_value\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=5, size=30)  # Simulated data\n",
        "one_sample_z_test(sample_data, population_mean=52, population_std=5)"
      ],
      "metadata": {
        "id": "iOa5UdjbKNsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python"
      ],
      "metadata": {
        "id": "NUNvD9LwKN2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Simulating Data for Hypothesis Testing and Calculating P-Value\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Reuse the function above and simulate random data\n",
        "np.random.seed(42)\n",
        "simulated_data = np.random.normal(loc=100, scale=15, size=50)\n",
        "one_sample_z_test(simulated_data, population_mean=105, population_std=15)\n"
      ],
      "metadata": {
        "id": "fur3qWcjKN5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean"
      ],
      "metadata": {
        "id": "SbMGIMKKKN87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "    standard_error = population_std / np.sqrt(sample_size)\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference.\")\n",
        "    return z_score, p_value"
      ],
      "metadata": {
        "id": "LKN1gI5OKOAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot"
      ],
      "metadata": {
        "id": "Vwoe2YbJKOEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Two-Tailed Z-Test with Visualization\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_two_tailed_z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    z_score, p_value = one_sample_z_test(sample_data, population_mean, population_std, alpha)\n",
        "    critical_value = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, y, label=\"Standard Normal Distribution\")\n",
        "    plt.fill_between(x, y, where=(x <= -critical_value) | (x >= critical_value), color=\"red\", alpha=0.3, label=\"Rejection Region\")\n",
        "    plt.axvline(z_score, color=\"blue\", linestyle=\"--\", label=f\"Z-Score: {z_score:.2f}\")\n",
        "    plt.title(\"Two-Tailed Z-Test with Decision Region\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Z-Score\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.show()\n",
        "\n",
        "# Example\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=5, size=30)\n",
        "visualize_two_tailed_z_test(sample_data, population_mean=52, population_std=5)"
      ],
      "metadata": {
        "id": "LL_af4lLKOJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing"
      ],
      "metadata": {
        "id": "9Act0HXbKONN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Function to Calculate and Visualize Type 1 and Type 2 Errors\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "def visualize_type1_type2_errors(alpha=0.05, effect_size=0.5, sample_size=30):\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    null_dist = norm.pdf(x)\n",
        "    alt_dist = norm.pdf(x, loc=effect_size)\n",
        "\n",
        "    critical_value = norm.ppf(1 - alpha)\n",
        "    type_1_region = x >= critical_value\n",
        "    type_2_region = (x < critical_value) & (alt_dist > 0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, null_dist, label=\"Null Distribution (H0)\")\n",
        "    plt.plot(x, alt_dist, label=\"Alternative Distribution (H1)\", linestyle=\"--\")\n",
        "    plt.fill_between(x, null_dist, where=type_1_region, color=\"red\", alpha=0.3, label=\"Type 1 Error\")\n",
        "    plt.fill_between(x, alt_dist, where=type_2_region, color=\"blue\", alpha=0.3, label=\"Type 2 Error\")\n",
        "    plt.axvline(critical_value, color=\"black\", linestyle=\"--\", label=f\"Critical Value: {critical_value:.2f}\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Type 1 and Type 2 Errors\")\n",
        "    plt.xlabel(\"Test Statistic\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.show()\n",
        "\n",
        "# Example\n",
        "visualize_type1_type2_errors(alpha=0.05, effect_size=1.0, sample_size=30)"
      ],
      "metadata": {
        "id": "f61Uj2e0dZy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.Write a Python program to perform an independent T-test and interpret the results"
      ],
      "metadata": {
        "id": "LSpuLAXldZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Independent T-Test\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "def independent_t_test(group1, group2, alpha=0.05):\n",
        "    t_stat, p_value = ttest_ind(group1, group2)\n",
        "    print(f\"T-Statistic: {t_stat}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: Significant difference between the groups.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference.\")\n",
        "    return t_stat, p_value\n",
        "\n",
        "# Example\n",
        "group1 = np.random.normal(60, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "independent_t_test(group1, group2)"
      ],
      "metadata": {
        "id": "C_8k9tivdaBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.Simulate data and perform both Z-test and T-test, then compare the results using Python@"
      ],
      "metadata": {
        "id": "6CnauLa5daFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Simulate Data and Compare Z-Test and T-Test\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Z-Test\n",
        "one_sample_z_test(sample_data, population_mean=52, population_std=5)\n",
        "\n",
        "# T-Test\n",
        "from scipy.stats import ttest_1samp\n",
        "t_stat, p_value = ttest_1samp(sample_data, 52)\n",
        "print(f\"T-Statistic: {t_stat}, P-Value: {p_value}\")"
      ],
      "metadata": {
        "id": "SoJsmG1AdaJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.Write a Python function to calculate the confidence interval for a sample mean and explain its significance."
      ],
      "metadata": {
        "id": "vW94GbftdaM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Confidence Interval for Sample Mean\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "def confidence_interval(sample_data, confidence=0.95):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_std = np.std(sample_data, ddof=1)\n",
        "    sample_size = len(sample_data)\n",
        "    standard_error = sample_std / np.sqrt(sample_size)\n",
        "    margin_of_error = norm.ppf((1 + confidence) / 2) * standard_error\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Confidence Interval: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example\n",
        "confidence_interval(sample_data)"
      ],
      "metadata": {
        "id": "es6wys2_daRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.Write a Python program to calculate the margin of error for a given confidence level using sample data."
      ],
      "metadata": {
        "id": "BI2uJ6zmdaWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import scipy.stats as stats\n",
        "\n",
        "def calculate_margin_of_error(sample_data, confidence_level):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for a given confidence level using sample data.\n",
        "\n",
        "    :param sample_data: List of sample data values (numeric).\n",
        "    :param confidence_level: Confidence level (e.g., 0.95 for 95%).\n",
        "    :return: Margin of error.\n",
        "    \"\"\"\n",
        "    # Calculate sample mean and standard deviation\n",
        "    sample_mean = sum(sample_data) / len(sample_data)\n",
        "    sample_std_dev = math.sqrt(sum((x - sample_mean) ** 2 for x in sample_data) / (len(sample_data) - 1))\n",
        "\n",
        "    # Determine the critical value (z or t)\n",
        "    degrees_of_freedom = len(sample_data) - 1\n",
        "    critical_value = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom)\n",
        "\n",
        "    # Calculate standard error\n",
        "    standard_error = sample_std_dev / math.sqrt(len(sample_data))\n",
        "\n",
        "    # Calculate margin of error\n",
        "    margin_of_error = critical_value * standard_error\n",
        "\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    sample_data = [23, 27, 25, 30, 22, 26, 24, 28, 29, 21]  # Replace with your sample data\n",
        "    confidence_level = 0.95  # 95% confidence level\n",
        "\n",
        "    margin_of_error = calculate_margin_of_error(sample_data, confidence_level)\n",
        "\n",
        "    print(f\"Margin of Error at {confidence_level * 100}% confidence level: {margin_of_error:.2f}\")\n"
      ],
      "metadata": {
        "id": "Bm8AO6iTdaaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "Bayesian inference uses Bayes' Theorem to update probabilities based on new evidence.\n",
        "\n",
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "def bayesian_inference(prior, likelihood, evidence):\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Example: Disease testing\n",
        "prior = 0.01  # Probability of disease (prior belief)\n",
        "likelihood = 0.95  # Probability of positive test given disease\n",
        "false_positive_rate = 0.05  # Probability of positive test without disease\n",
        "evidence = (likelihood * prior) + (false_positive_rate * (1 - prior))\n",
        "\n",
        "posterior = bayesian_inference(prior, likelihood, evidence)\n",
        "print(f\"Posterior probability: {posterior:.4f}\")"
      ],
      "metadata": {
        "id": "okPeCVIudafr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12.Perform a Chi-square test for independence between two categorical variables in Python"
      ],
      "metadata": {
        "id": "llv2nXbRdakE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The test assesses whether two categorical variables are independent.\n",
        "\n",
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Example data\n",
        "data = [[50, 30], [20, 100]]\n",
        "df = pd.DataFrame(data, columns=[\"Category1\", \"Category2\"], index=[\"Group1\", \"Group2\"])\n",
        "\n",
        "# Perform Chi-Square Test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "print(f\"Chi-Square Statistic: {chi2}, p-value: {p}\")"
      ],
      "metadata": {
        "id": "tfP6Rg7JkEZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.Write a Python program to calculate the expected frequencies for a Chi-square test based on observed"
      ],
      "metadata": {
        "id": "__tCHVaAdatQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Observed data\n",
        "observed = np.array([[50, 30], [20, 100]])\n",
        "\n",
        "# Calculate row and column sums\n",
        "row_totals = observed.sum(axis=1)\n",
        "col_totals = observed.sum(axis=0)\n",
        "grand_total = observed.sum()\n",
        "\n",
        "# Calculate expected frequencies\n",
        "expected = np.outer(row_totals, col_totals) / grand_total\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "S4EJ7ZPekBuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution"
      ],
      "metadata": {
        "id": "4RpoCPJvda22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "This test compares observed data to an expected distribution.\n",
        "\n",
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed and expected data\n",
        "observed = [50, 30, 20]\n",
        "expected = [40, 40, 20]\n",
        "\n",
        "# Perform goodness-of-fit test\n",
        "chi2, p = chisquare(f_obs=observed, f_exp=expected)\n",
        "print(f\"Chi-Square Statistic: {chi2}, p-value: {p}\")\n"
      ],
      "metadata": {
        "id": "8ncY7x4qfH5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics"
      ],
      "metadata": {
        "id": "c7A9lYBwfIBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "This test compares observed data to an expected distribution.\n",
        "\n",
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed and expected data\n",
        "observed = [50, 30, 20]\n",
        "expected = [40, 40, 20]\n",
        "\n",
        "# Perform goodness-of-fit test\n",
        "chi2, p = chisquare(f_obs=observed, f_exp=expected)\n",
        "print(f\"Chi-Square Statistic: {chi2}, p-value: {p}\")"
      ],
      "metadata": {
        "id": "kDZZjfySfIJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16.Implement an F-test using Python to compare the variances of two random samples."
      ],
      "metadata": {
        "id": "1wyeL0TQfIOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f\n",
        "\n",
        "# Sample variances and sizes\n",
        "var1, n1 = 5.2, 30\n",
        "var2, n2 = 2.8, 30\n",
        "\n",
        "# F-Test\n",
        "f_stat = var1 / var2\n",
        "p_value = f.sf(f_stat, dfn=n1-1, dfd=n2-1)\n",
        "print(f\"F-Statistic: {f_stat}, p-value: {p_value}\")"
      ],
      "metadata": {
        "id": "9fzHZkw6fITR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "#interpret the resultsD"
      ],
      "metadata": {
        "id": "e0ClD3dXfIZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Sample data\n",
        "group1 = [5, 6, 7, 8]\n",
        "group2 = [8, 9, 10, 11]\n",
        "group3 = [7, 8, 9, 10]\n",
        "\n",
        "# One-way ANOVA\n",
        "f_stat, p = f_oneway(group1, group2, group3)\n",
        "print(f\"F-Statistic: {f_stat}, p-value: {p}\")"
      ],
      "metadata": {
        "id": "OioKRF6YfIgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18.Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results"
      ],
      "metadata": {
        "id": "7cdTrRXQfIlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Example data\n",
        "data = pd.DataFrame({\n",
        "    'Value': [5, 6, 7, 8, 8, 9, 10, 11, 7, 8, 9, 10],\n",
        "    'Group': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C']\n",
        "})\n",
        "\n",
        "# ANOVA\n",
        "groups = [data[data['Group'] == g]['Value'] for g in data['Group'].unique()]\n",
        "f_stat, p = f_oneway(*groups)\n",
        "print(f\"F-Statistic: {f_stat}, p-value: {p}\")\n",
        "\n",
        "# Visualization\n",
        "sns.boxplot(x=\"Group\", y=\"Value\", data=data)\n",
        "plt.title(\"One-Way ANOVA Results\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eeLIa6J5fI2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19.Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVAD"
      ],
      "metadata": {
        "id": "bK1KYqncfI8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_assumptions(data, groups):\n",
        "    # Normality check (Shapiro-Wilk Test)\n",
        "    for g in groups:\n",
        "        stat, p = shapiro(data[data['Group'] == g]['Value'])\n",
        "        print(f\"Group {g}: Shapiro-Wilk p-value = {p}\")\n",
        "\n",
        "    # Equal variance check (Levene's Test)\n",
        "    samples = [data[data['Group'] == g]['Value'] for g in groups]\n",
        "    stat, p = levene(*samples)\n",
        "    print(f\"Levene's Test p-value = {p}\")\n",
        "\n",
        "# Example\n",
        "check_assumptions(data, data['Group'].unique())"
      ],
      "metadata": {
        "id": "1r6eBrD2fmXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the\n",
        "#resultsD"
      ],
      "metadata": {
        "id": "QczlhYN0fmk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Code Example:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Example data\n",
        "data = pd.DataFrame({\n",
        "    'Value': [5, 6, 7, 8, 8, 9, 10, 11, 7, 8, 9, 10],\n",
        "    'Factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
        "    'Factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y']\n",
        "})\n",
        "\n",
        "# Two-Way ANOVA\n",
        "model = ols('Value ~ C(Factor1) + C(Factor2) + C(Factor1):C(Factor2)', data=data).fit()\n",
        "anova_results = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_results)\n",
        "These examples demonstrate essential statistical methods in Python with appropriate tools like SciPy, StatsModels, and Matplotlib."
      ],
      "metadata": {
        "id": "kTnKQaa9fmzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21.Write a Python program to visualize the F-distribution and discuss its use in hypothesis testingD"
      ],
      "metadata": {
        "id": "pHmAcXGlfm_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Visualizing the F-distribution and its Use in Hypothesis Testing\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Parameters for F-distribution\n",
        "dof1, dof2 = 5, 10  # Degrees of freedom\n",
        "x = np.linspace(0.01, 5, 500)\n",
        "pdf = f.pdf(x, dof1, dof2)\n",
        "\n",
        "# Plotting the F-distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, pdf, label=f'F-distribution (df1={dof1}, df2={dof2})', color='blue')\n",
        "plt.title(\"F-Distribution\")\n",
        "plt.xlabel(\"F-value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Use in hypothesis testing: comparing variances\n",
        "print(\"The F-distribution is used to compare variances in ANOVA or variance ratio tests.\")"
      ],
      "metadata": {
        "id": "HN45Y93ifx3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22.D Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group meansD"
      ],
      "metadata": {
        "id": "BRasvFjKfyCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "One-Way ANOVA Test and Boxplots\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulating data\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 12, 30)\n",
        "group3 = np.random.normal(60, 15, 30)\n",
        "\n",
        "# One-Way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Visualizing with boxplots\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=[group1, group2, group3], notch=True)\n",
        "plt.xticks([0, 1, 2], [\"Group 1\", \"Group 2\", \"Group 3\"])\n",
        "plt.title(\"Boxplots of Groups\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference between groups (reject H0).\")\n",
        "else:\n",
        "    print(\"No significant difference between groups (fail to reject H0).\")"
      ],
      "metadata": {
        "id": "VADe5WwOfyK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23.Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means.\n"
      ],
      "metadata": {
        "id": "4qTyfSC3fySO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating data\n",
        "data1 = np.random.normal(50, 5, 100)\n",
        "data2 = np.random.normal(55, 5, 100)\n",
        "\n",
        "# Performing t-test\n",
        "t_stat, p_value = stats.ttest_ind(data1, data2)\n",
        "\n",
        "# Results\n",
        "print(f\"T-statistic: {t_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Means are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in means.\")"
      ],
      "metadata": {
        "id": "vaHqAPe0liWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24.Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results"
      ],
      "metadata": {
        "id": "ICd5C20BfyYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating data\n",
        "data = np.random.normal(50, 10, 100)\n",
        "sample_variance = np.var(data, ddof=1)\n",
        "pop_variance = 100  # Hypothetical population variance\n",
        "\n",
        "# Chi-square statistic\n",
        "chi_square_stat = (len(data) - 1) * sample_variance / pop_variance\n",
        "p_value = 1 - stats.chi2.cdf(chi_square_stat, df=len(data)-1)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi_square_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Variance differs from population variance.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Variance matches population variance.\")"
      ],
      "metadata": {
        "id": "n3rpRG9fiqUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups"
      ],
      "metadata": {
        "id": "ugGbyup3iqdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Example data\n",
        "success1, n1 = 50, 200  # Group 1: successes, total\n",
        "success2, n2 = 30, 150  # Group 2: successes, total\n",
        "\n",
        "# Z-test\n",
        "count = np.array([success1, success2])\n",
        "nobs = np.array([n1, n2])\n",
        "z_stat, p_value = proportions_ztest(count, nobs)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in proportions.\")\n"
      ],
      "metadata": {
        "id": "oohTO9swiqlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26.Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results"
      ],
      "metadata": {
        "id": "eQkqbccJiqqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F-Test for Comparing Variances\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Simulating data\n",
        "data1 = np.random.normal(50, 5, 100)\n",
        "data2 = np.random.normal(50, 10, 100)\n",
        "\n",
        "# F-test\n",
        "f_stat = np.var(data1, ddof=1) / np.var(data2, ddof=1)\n",
        "df1, df2 = len(data1) - 1, len(data2) - 1\n",
        "p_value = 1 - stats.f.cdf(f_stat, df1, df2)\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variances.\")"
      ],
      "metadata": {
        "id": "hTqsiIpfiqyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27.Perform a Chi-square test for goodness of fit with simulated data and analyze the results."
      ],
      "metadata": {
        "id": "AVAVsW8Tiz_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chi-Square Test for Goodness of Fit\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "# Simulated data\n",
        "observed = np.array([25, 30, 45])\n",
        "expected = np.array([30, 30, 40])\n",
        "\n",
        "# Chi-square test\n",
        "chi_square_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi_square_stat:.2f}, p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: Observed distribution differs from expected.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Observed matches expected distribution.\")\n",
        "These scripts include data visualization and hypothesis testing techniques that are essential in statistics. Let me know if you need detailed explanations for any part!"
      ],
      "metadata": {
        "id": "wVpqCkyoi4BG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}